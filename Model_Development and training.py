# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ib6mLq0bmHlI0WN1kM9KrO3nXAiPL5sk
"""

import os
os.listdir("/content")

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


ny_master = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
ny_master.columns = ny_master.columns.str.strip().str.lower()


target = "gvw"
features = ["class", "num_axles"]

results = []


for lane in sorted(ny_master["lane"].unique()):
    lane_data = ny_master[ny_master["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=3,
            objective="reg:squarederror",
            subsample=1.0,
            colsample_bytree=1.0,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)


        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)


        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R2": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/NewYork_XGB_Results_2features.csv"
results_df.to_csv(output_path, index=False)

print(f"âœ… Results saved to {output_path}")
print(results_df.head(20))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
df.columns = df.columns.str.strip().str.lower()


target = "gvw"
features = ["class", "num_axles"]

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=100,
            learning_rate=0.05,
            max_depth=3,
            subsample=0.6,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)


        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R2": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/NewYork_XGB_Results_TwoFeatures.csv"
results_df.to_csv(output_path, index=False)

print(f" Results saved to {output_path}")
print(reults_df.head(20))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


file_path = "/content/NewYork_Combined_Ordered.csv"
df = pd.read_csv(file_path)
df.columns = df.columns.str.strip().str.lower()


target = "gvw"
features = ["class", "num_axles", "hour"]

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=100,
            learning_rate=0.05,
            max_depth=3,
            subsample=0.6,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R2": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_csv = "/content/NewYork_XGB_Results_ThreeFeatures.csv"
results_df.to_csv(output_csv, index=False)

print(f" Results saved to: {output_csv}")
print(results_df.head(20))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
df.columns = df.columns.str.strip().str.lower()


features = ["class", "num_axles", "hour", "speed"]
target = "gvw"

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=100,
            learning_rate=0.05,
            max_depth=3,
            subsample=0.6,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R2": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/NewYork_XGB_Results_FourFeatures.csv"
results_df.to_csv(output_path, index=False)

print("âœ… Results saved to:", output_path)
print(results_df.head(20))

from google.colab import files
import os


print("ðŸ“¤ Please select your three files:")
uploaded = files.upload()


print("\nâœ… Uploaded files:")
for fn in uploaded.keys():
    print(" -", fn)


print("\nðŸ“‚ Files currently in /content:")
print(os.listdir("/content"))

import zipfile, os

zip_path = "/content/texas_master.zip"
extract_path = "/content/"


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)


print("âœ… Extracted files:")
print(os.listdir(extract_path))

import pandas as pd


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=["lane","gvw"])
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=["lane","gvw"])
tx = pd.read_csv("/content/texas_master.csv", usecols=["lane","vehicle class","gvw"])


tx.rename(columns={"vehicle class": "class"}, inplace=True)


for df in [ny, ca, tx]:
    df["gvw"] = pd.to_numeric(df["gvw"], errors="coerce")
    df.dropna(subset=["gvw"], inplace=True)

print("âœ… Data loaded successfully!")
print("New York:", ny.shape)
print("California:", ca.shape)
print("Texas:", tx.shape)

import matplotlib.pyplot as plt

def plot_gvw_density(df, state_name, lanes, filename):
    plt.figure(figsize=(10,4))
    for lane in lanes:
        subset = df[df["lane"]==lane]["gvw"].sample(min(50000, len(df[df["lane"]==lane]["gvw"])), random_state=42)
        subset.plot(kind="density", linewidth=2, label=f"Lane {lane}")
    plt.title(f"Probability Density of Trucks by Gross Weight\n({state_name}, USA)  (January to December)", fontsize=11)
    plt.xlabel("Gross Vehicle Weight (lbs)")
    plt.ylabel("Probability Density")
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(filename, dpi=300)
    plt.show()
    print(f"âœ… Saved: {filename}")

plot_gvw_density(ny, "New York", [1,2,3], "/content/NewYork_PD.png")
plot_gvw_density(ca, "California", [1,2,3], "/content/California_PD.png")
plot_gvw_density(tx, "Texas", [1,2,3,4], "/content/Texas_PD.png")

from google.colab import files
files.download("/content/NewYork_PD.png")
files.download("/content/California_PD.png")
files.download("/content/Texas_PD.png")

from google.colab import files
files.download("/content/NewYork_PD_Final.png")
files.download("/content/California_PD_Final.png")
files.download("/content/Texas_PD_Final.png")

print("New York GVW summary:")
print(ny["gvw"].describe(), "\n")

print("California GVW summary:")
print(ca["gvw"].describe(), "\n")

print("Texas GVW summary:")
print(tx["gvw"].describe(), "\n")

import matplotlib.pyplot as plt
import numpy as np

def plot_gvw_density_final_kips(df, state_name, lanes, filename):
    plt.figure(figsize=(10, 4))

    for lane in lanes:
        subset = df[df["lane"] == lane]["gvw"].dropna()
        if subset.empty:
            print(f"âš ï¸ Lane {lane} has no data.")
            continue


        subset = subset[(subset > 5) & (subset < 180)]
        if subset.empty:
            print(f"âš ï¸ Lane {lane} has no data in 5â€“180 kips range, skipped.")
            continue

        subset = subset.sample(min(50000, len(subset)), random_state=42)
        subset.plot(kind="density", linewidth=2, label=f"Lane {lane}")

    plt.title(f"Probability Density of Trucks by Gross Weight\n({state_name}, USA) (January to December)",
              fontsize=11, fontweight="bold")
    plt.xlabel("Gross Vehicle Weight (Ã—1000 lbs)", fontsize=10)
    plt.ylabel("Probability Density", fontsize=10)
    plt.xlim(0, 180)
    plt.ylim(0, 0.12)
    plt.xticks(np.arange(0, 181, 20))
    plt.yticks(np.arange(0, 0.13, 0.02))
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(filename, dpi=400)
    plt.show()
    print(f"âœ… Saved â†’ {filename}")

plot_gvw_density_final_kips(ny, "New York", [1,2,3], "/content/NewYork_PD_FinalKips.png")
plot_gvw_density_final_kips(ca, "California", [1,2,3], "/content/California_PD_FinalKips.png")
plot_gvw_density_final_kips(tx, "Texas", [1,2,3,4], "/content/Texas_PD_FinalKips.png")

from google.colab import files
files.download("/content/NewYork_PD_FinalKips.png")

files.download("/content/California_PD_FinalKips.png")

files.download("/content/Texas_PD_FinalKips.png")

import zipfile
import os

zip_path = "/content/California_Combined_Ordered.zip"


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/")
    print("âœ… California file extracted!")


print("\nExtracted files:")
print(os.listdir("/content/"))

import pandas as pd


df = pd.read_csv("/content/California_Combined_Ordered.csv")


print("âœ… California Dataset Loaded")
print("Shape:", df.shape)
print("\nColumn names:\n", list(df.columns))


print("\nData types and missing value counts:\n")
print(df.info())


print("\nDescriptive Statistics (first 10 columns):\n")
print(df.describe(include='all').transpose().head(10))


print("\nSample of the dataset:\n")
print(df.head(10))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import matplotlib.pyplot as plt

df = pd.read_csv("/content/California_Combined_Ordered.csv")
print("âœ… California dataset loaded successfully!")
print("Shape:", df.shape)


df['Month'] = df['Month'].astype('category').cat.codes


X = df.drop(columns=['gvw'])
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


model = xgb.XGBRegressor(
    n_estimators=150,
    learning_rate=0.05,
    max_depth=4,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


results = pd.DataFrame({
    'Metric': ['RMSE (kN)', 'MAE (kN)', 'MAPE (%)', 'RÂ²'],
    'Value': [round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3)]
})

print("\nðŸ“Š Model Performance on California Dataset:\n")
print(results.to_string(index=False))


plt.figure(figsize=(8, 6))
xgb.plot_importance(model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for GVW Prediction (California)", fontsize=13)
plt.tight_layout()
plt.show()


results.to_csv("/content/California_XGBoost_Performance.csv", index=False)
print("\nâœ… Results saved as: /content/California_XGBoost_Performance.csv")

from google.colab import files
uploaded = files.upload()

import zipfile, os


zip_path = "/content/texas_master.zip"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content")

print("âœ… Texas file extracted successfully!\nExtracted files:")
print(os.listdir("/content"))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


df = pd.read_csv("/content/texas_master.csv")
print("âœ… Texas dataset loaded successfully!")
print("Shape:", df.shape)
print("\nColumns:", list(df.columns))

print("\nData info before encoding:\n")
print(df.info())


if df['Month'].dtype == 'object':
    df['Month'] = df['Month'].astype('category').cat.codes


X = df.drop(columns=['gvw'])
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


model = xgb.XGBRegressor(
    n_estimators=150,
    learning_rate=0.05,
    max_depth=4,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


results = pd.DataFrame({
    'Metric': ['RMSE (kN)', 'MAE (kN)', 'MAPE (%)', 'RÂ²'],
    'Value': [round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3)]
})

print("\nðŸ“Š Model Performance on Texas Dataset:\n")
print(results.to_string(index=False))


plt.figure(figsize=(8, 6))
xgb.plot_importance(model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for GVW Prediction (Texas)", fontsize=13)
plt.tight_layout()
plt.show()


results.to_csv("/content/Texas_XGBoost_Performance.csv", index=False)
print("\nâœ… Results saved as: /content/Texas_XGBoost_Performance.csv")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


df = pd.read_csv("/content/texas_master.csv", low_memory=False)

print("âœ… Texas dataset loaded successfully!")
print("Shape:", df.shape)


for col in df.select_dtypes(include=['float64', 'int64']).columns:
    df[col] = pd.to_numeric(df[col], downcast='float')


df_sample = df.sample(frac=0.07, random_state=42)
print("Sample size used:", df_sample.shape)


if df_sample['Month'].dtype == 'object':
    df_sample['Month'] = df_sample['Month'].astype('category').cat.codes


X = df_sample.drop(columns=['gvw'])
y = df_sample['gvw']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.7,
    colsample_bytree=0.8,
    tree_method='hist',
    random_state=42
)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)

results = pd.DataFrame({
    'Metric': ['RMSE (kN)', 'MAE (kN)', 'MAPE (%)', 'RÂ²'],
    'Value': [round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3)]
})

print("\nðŸ“Š Model Performance (Texas Sample):\n")
print(results.to_string(index=False))


plt.figure(figsize=(8, 6))
xgb.plot_importance(model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for GVW Prediction (Texas - Sample)", fontsize=13)
plt.tight_layout()
plt.show()

results.to_csv("/content/Texas_XGBoost_Performance_Sample.csv", index=False)
print("\nâœ… Results saved as: /content/Texas_XGBoost_Performance_Sample.csv")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


df = pd.read_csv("/content/texas_master.csv", nrows=500000, low_memory=False)
print("âœ… Loaded subset:", df.shape)
print("Columns:", list(df.columns))


drop_cols = [c for c in ['Dir', 'month_name'] if c in df.columns]
df = df.drop(columns=drop_cols)
print("Dropped columns:", drop_cols)


df.rename(columns={
    'vehicle class': 'class',
    'number of axle': 'axles'
}, inplace=True)


for col in df.select_dtypes(include=['float64', 'int64']).columns:
    df[col] = pd.to_numeric(df[col], downcast='float')

X = df.drop(columns=['gvw'])
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


model = xgb.XGBRegressor(
    n_estimators=80,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.7,
    colsample_bytree=0.8,
    tree_method='hist',
    random_state=42
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae  = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2   = r2_score(y_test, y_pred)

results = pd.DataFrame({
    'Metric': ['RMSE (kN)', 'MAE (kN)', 'MAPE (%)', 'RÂ²'],
    'Value': [round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3)]
})
print("\nðŸ“Š Model Performance (Texas subset):\n")
print(results.to_string(index=False))


plt.figure(figsize=(8, 6))
xgb.plot_importance(model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for GVW Prediction (Texas subset)", fontsize=13)
plt.tight_layout()
plt.show()


results.to_csv("/content/Texas_XGBoost_Performance_Cleaned.csv", index=False)
print("\nâœ… Results saved as: /content/Texas_XGBoost_Performance_Cleaned.csv")