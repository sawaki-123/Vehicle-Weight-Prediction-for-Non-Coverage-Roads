# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZQvzZUcrl6ACB-o5RKiCauDPFBHFF1QB
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
df.columns = df.columns.str.strip().str.lower()


features = ["class"]
target = "gvw"

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=3,
            subsample=0.8,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)


        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R¬≤": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/NewYork_XGB_ClassOnly.csv"
results_df.to_csv(output_path, index=False)

print(" Results saved to:", output_path)
print(results_df.to_string(index=False))

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


df = pd.read_csv("/content/California_Combined_Ordered.csv")
df.columns = df.columns.str.strip().str.lower()


features = ["class"]
target = "gvw"

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=3,
            subsample=0.8,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)


        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)


        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R¬≤": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/California_XGB_ClassOnly.csv"
results_df.to_csv(output_path, index=False)

print("‚úÖ Results saved to:", output_path)
print(results_df.to_string(index=False))

from google.colab import files
uploaded = files.upload()



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
df.columns = df.columns.str.strip().str.lower()


features = ["class", "num_axles"]
target = "gvw"

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


            n_estimators=200,
            learning_rate=0.1,
            max_depth=4,
            subsample=0.8,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R¬≤": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/NewYork_XGB_Class_NumAxles.csv"
results_df.to_csv(output_path, index=False)

print("‚úÖ Results saved to:", output_path)
print(results_df.to_string(index=False))

from google.colab import files
files.download(output_path)

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


df = pd.read_csv("/content/California_Combined_Ordered.csv")
df.columns = df.columns.str.strip().str.lower()


features = ["class", "num_axles"]
target = "gvw"

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R¬≤": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/California_XGB_Class_NumAxles.csv"
results_df.to_csv(output_path, index=False)

print("‚úÖts saved to:", output_path)
print(results_df.to_string(index=False))

from google.colab import files
files.download(output_path)

from google.colab import files
uploaded = files.upload()

import os
print(os.listdir("/content"))

from google.colab import files
uploaded = files.upload()

import os
print(os.listdir("/content"))

import zipfile
import os

zip_path = "/content/texas_master.zip"
extract_path = "/content/texas_master/"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Extracted files:", os.listdir(extract_path))

import zipfile, os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor

zip_path = "/content/texas_master.zip"
extract_path = "/content/texas_master/"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Extracted files:", os.listdir(extract_path))


csv_files = [f for f in os.listdir(extract_path) if f.endswith(".csv")]
print("CSV files found:", csv_files)


df = pd.read_csv(os.path.join(extract_path, csv_files[0]))
df.columns = df.columns.str.strip().str.lower()


df.rename(columns={
    "vehicle class": "class",
    "number of axle": "num_axles"
}, inplace=True)


features = ["class", "num_axles"]
target = "gvw"

results = []


for lane in sorted(df["lane"].unique()):
    lane_data = df[df["lane"] == lane]

    for cls in sorted(lane_data["class"].unique()):
        class_data = lane_data[lane_data["class"] == cls]

        if len(class_data) < 50:
            continue

        X = class_data[features]
        y = class_data[target]


        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )


        model = XGBRegressor(
            n_estimators=200,
            learning_rate=0.1,
            max_depth=4,
            subsample=0.8,
            colsample_bytree=0.8,
            objective="reg:squarederror",
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)


        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        mape = (abs((y_test - y_pred) / y_test).mean()) * 100
        r2 = r2_score(y_test, y_pred)

        results.append({
            "Lane": lane,
            "Class": cls,
            "RMSE": round(rmse, 2),
            "MAE": round(mae, 2),
            "MAPE (%)": round(mape, 2),
            "R¬≤": round(r2, 3)
        })


results_df = pd.DataFrame(results)
output_path = "/content/Texas_XGB_Class_NumAxles.csv"
results_df.to_csv(output_path, index=False)

print("‚úÖ Results saved to:", output_path)
print(results_df.to_string(index=False))

from google.colab import files
files.download(output_path)

import pandas as pd


ny = pd.read_csv("/content/NewYork_XGB_Class_NumAxles.csv")
ca = pd.read_csv("/content/California_XGB_Class_NumAxles.csv")
tx = pd.read_csv("/content/Texas_XGB_Class_NumAxles.csv")


ny = ny[["Lane", "Class", "RMSE", "MAE", "MAPE (%)"]].rename(
    columns={"RMSE":"NY (RMSE)", "MAE":"NY (MAE)", "MAPE (%)":"NY (MAPE)"}
)
ca = ca[["Lane", "Class", "RMSE", "MAE", "MAPE (%)"]].rename(
    columns={"RMSE":"CA (RMSE)", "MAE":"CA (MAE)", "MAPE (%)":"CA (MAPE)"}
)
tx = tx[["Lane", "Class", "RMSE", "MAE", "MAPE (%)"]].rename(
    columns={"RMSE":"Texas (RMSE)", "MAE":"Texas (MAE)", "MAPE (%)":"Texas (MAPE)"}
)


merged = ny.merge(ca, on=["Lane","Class"], how="outer").merge(tx, on=["Lane","Class"], how="outer")


merged = merged.sort_values(by=["Lane","Class"]).reset_index(drop=True)


output_path = "/content/XGB_Comparison_AllStates.csv"
merged.to_csv(output_path, index=False)

print("‚úÖ Combined results saved to:", output_path)
print(merged.to_string(index=False))

from google.colab import files
files.download(output_path)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from xgboost import XGBRegressor


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
ca = pd.read_csv("/content/California_Combined_Ordered.csv")
tx = pd.read_csv("/content/texas_master/texas_master.csv")


ny.columns = ny.columns.str.strip().str.lower()
ca.columns = ca.columns.str.strip().str.lower()
tx.columns = tx.columns.str.strip().str.lower()


tx.rename(columns={"vehicle class": "class", "number of axle": "num_axles"}, inplace=True)


features = ["class"]
target = "gvw"


X = ny[features]
y = ny[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

ny_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    colsample_bytree=0.8,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1
)
ny_model.fit(X_train, y_train)

print("‚úÖ New York model trained with vehicle class only.")


def evaluate_transfer(df, state_name):
    results = []
    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X_test = class_data[features]
            y_test = class_data[target]


            y_pred = ny_model.predict(X_test)


            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = (abs((y_test - y_pred) / y_test).mean()) * 100

            results.append({
                "Lane": lane,
                "Class": cls,
                f"{state_name} (RMSE)": round(rmse, 2),
                f"{state_name} (MAE)": round(mae, 2),
                f"{state_name} (MAPE)": f"{round(mape, 2)}%"
            })
    return pd.DataFrame(results)


ca_results = evaluate_transfer(ca, "CA")
tx_results = evaluate_transfer(tx, "Texas")


merged = ca_results.merge(tx_results, on=["Lane", "Class"], how="outer")


output_path = "/content/NY_Model_Transfer_ClassOnly.csv"
merged.to_csv(output_path, index=False)

print("‚úÖ Transferability results saved to:", output_path)
print(merged.to_string(index=False))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from xgboost import XGBRegressor


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
ca = pd.read_csv("/content/California_Combined_Ordered.csv")
tx = pd.read_csv("/content/texas_master/texas_master.csv")


ny.columns = ny.columns.str.strip().str.lower()
ca.columns = ca.columns.str.strip().str.lower()
tx.columns = tx.columns.str.strip().str.lower()


tx.rename(columns={"vehicle class": "class", "number of axle": "num_axles"}, inplace=True)


ny_sample = (
    ny.groupby("class", group_keys=False)
      .apply(lambda x: x.sample(min(len(x), 5000), random_state=42))
)

print("NY sample size after balanced sampling:", len(ny_sample))

for df_tmp in [ny_sample, ca, tx]:
    if "class" in df_tmp.columns:
        df_tmp["class"] = df_tmp["class"].astype("int8")
    if "gvw" in df_tmp.columns:
        df_tmp["gvw"] = df_tmp["gvw"].astype("float32")


features = ["class"]
target = "gvw"

X = ny_sample[features]
y = ny_sample[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

ny_model = XGBRegressor(
    n_estimators=50,
    learning_rate=0.1,
    max_depth=3,
    colsample_bytree=0.8,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1,
    tree_method="hist",
    max_bin=64
)
ny_model.fit(X_train, y_train)

print("‚úÖ New York model trained with balanced sample.")


def evaluate_transfer(df, state_name):
    results = []
    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X_test = class_data[features]
            y_test = class_data[target]

            # Predict
            y_pred = ny_model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = (abs((y_test - y_pred) / y_test).mean()) * 100

            results.append({
                "Lane": lane,
                "Class": cls,
                f"{state_name} (RMSE)": round(rmse, 2),
                f"{state_name} (MAE)": round(mae, 2),
                f"{state_name} (MAPE)": f"{round(mape, 2)}%"
            })
    return pd.DataFrame(results)


ca_results = evaluate_transfer(ca, "CA")
tx_results = evaluate_transfer(tx, "Texas")

merged = ca_results.merge(tx_results, on=["Lane", "Class"], how="outer")


output_path = "/content/NY_Model_Transfer_ClassOnly_Balanced.csv"
merged.to_csv(output_path, index=False)

print("‚úÖ Transferability results saved to:", output_path)
print(merged.head(20).to_string(index=False))

import zipfile
import os


zip_path = "/content/texas_master.zip"
extract_path = "/content/"


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Extracted files:", os.listdir(extract_path))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from xgboost import XGBRegressor


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
ca = pd.read_csv("/content/California_Combined_Ordered.csv")
tx = pd.read_csv("/content/texas_master/texas_master.csv")


ny.columns = ny.columns.str.strip().str.lower()
ca.columns = ca.columns.str.strip().str.lower()
tx.columns = tx.columns.str.strip().str.lower()


tx.rename(columns={"vehicle class": "class", "number of axle": "num_axles"}, inplace=True)


features = ["class"]
target = "gvw"


ny_sample = ny.sample(frac=0.02, random_state=42)

ny_sample["class"] = ny_sample["class"].astype("int8")
ny_sample["gvw"] = ny_sample["gvw"].astype("float32")


X = ny_sample[features]
y = ny_sample[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


ny_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    colsample_bytree=0.8,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1,
    tree_method="hist"
)
ny_model.fit(X_train, y_train)

print("‚úÖ New York model trained on sampled data (vehicle class only).")


def evaluate_transfer(df, state_name):
    results = []
    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X_test = class_data[features]
            y_test = class_data[target]


            X_test["class"] = X_test["class"].astype("int8")
            y_test = y_test.astype("float32")

            y_pred = ny_model.predict(X_test)


            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = (abs((y_test - y_pred) / y_test).mean()) * 100

            results.append({
                "Lane": lane,
                "Class": cls,
                f"{state_name} (RMSE)": round(rmse, 2),
                f"{state_name} (MAE)": round(mae, 2),
                f"{state_name} (MAPE)": f"{round(mape, 2)}%"
            })
    return pd.DataFrame(results)


ca_results = evaluate_transfer(ca, "CA")
tx_results = evaluate_transfer(tx, "Texas")

merged = ca_results.merge(tx_results, on=["Lane", "Class"], how="outer")


output_path = "/content/NY_Model_Transfer_ClassOnly_Optimized.csv"
merged.to_csv(output_path, index=False)

print("‚úÖ Transferability results saved to:", output_path)
print(merged.head(20).to_string(index=False))

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

import zipfile, os


zip_path = "/content/texas_master.zip"
extract_path = "/content/"


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)


print("Extracted files:", os.listdir(extract_path))

import pandas as pd
import numpy as np
from xgboost import XGBRegressor

# === 1. Load datasets ===
ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
ca = pd.read_csv("/content/California_Combined_Ordered.csv")
tx = pd.read_csv("/content/texas_master.csv")


ny.columns = ny.columns.str.strip().str.lower()
ca.columns = ca.columns.str.strip().str.lower()
tx.columns = tx.columns.str.strip().str.lower()


tx.rename(columns={"vehicle class": "class", "number of axle": "num_axles"}, inplace=True)


ny_agg.rename(columns={"gvw":"avg_gvw"}, inplace=True)


X = ny_agg[["class"]]
y = ny_agg["avg_gvw"]


ny_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    colsample_bytree=0.8,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1,
    tree_method="hist"
)
ny_model.fit(X, y)

print("‚úÖ New York model trained on aggregated lane-class averages.")


def evaluate_transfer_agg(df, state_name):
    results = []
    df_agg = df.groupby(["lane","class"], as_index=False)["gvw"].mean()
    for _, row in df_agg.iterrows():
        lane = row["lane"]
        cls = row["class"]
        true_gvw = row["gvw"]
        pred_gvw = ny_model.predict([[cls]])[0]

        abs_error = abs(pred_gvw - true_gvw)
        mape = abs_error / true_gvw * 100 if true_gvw != 0 else np.nan

        results.append({
            "Lane": lane,
            "Class": cls,
            f"{state_name} (RMSE)": round(abs_error, 2),
            f"{state_name} (MAE)": round(abs_error, 2),
            f"{state_name} (MAPE)": f"{round(mape, 2)}%"
        })
    return pd.DataFrame(results)


ca_results = evaluate_transfer_agg(ca, "CA")
tx_results = evaluate_transfer_agg(tx, "Texas")


merged = ca_results.merge(tx_results, on=["Lane","Class"], how="outer")


output_path = "/content/NY_Model_Transfer_ClassOnly_Aggregated.csv"
merged.to_csv(output_path, index=False)

print("‚úÖ Transferability results saved to:", output_path)
print(merged.head(20).to_string(index=False))

import pandas as pd
import numpy as np
from xgboost import XGBRegressor


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=["lane","class","gvw"])
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=["lane","class","gvw"])
tx = pd.read_csv("/content/texas_master.csv", usecols=["lane","vehicle class","gvw"])


tx.rename(columns={"vehicle class": "class"}, inplace=True)


ny_agg = ny.groupby(["lane","class"], as_index=False)["gvw"].mean()
ny_agg.rename(columns={"gvw":"avg_gvw"}, inplace=True)

ca_agg = ca.groupby(["lane","class"], as_index=False)["gvw"].mean()
tx_agg = tx.groupby(["lane","class"], as_index=False)["gvw"].mean()

print("‚úÖ Aggregation complete: NY", ny_agg.shape, "CA", ca_agg.shape, "TX", tx_agg.shape)


X = ny_agg[["class"]]
y = ny_agg["avg_gvw"]

ny_model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    colsample_bytree=0.8,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1,
    tree_method="hist"
)
ny_model.fit(X, y)

print("‚úÖ New York model trained on aggregated lane-class averages.")


def evaluate_transfer_agg(df, state_name):
    results = []
    for _, row in df.iterrows():
        lane = row["lane"]
        cls = row["class"]
        true_gvw = row["gvw"]
        pred_gvw = ny_model.predict([[cls]])[0]

        abs_error = abs(pred_gvw - true_gvw)
        mape = abs_error / true_gvw * 100 if true_gvw != 0 else np.nan

        results.append({
            "Lane": lane,
            "Class": cls,
            f"{state_name} (RMSE)": round(abs_error, 2),
            f"{state_name} (MAE)": round(abs_error, 2),
            f"{state_name} (MAPE)": f"{round(mape, 2)}%"
        })
    return pd.DataFrame(results)

ca_results = evaluate_transfer_agg(ca_agg, "CA")
tx_results = evaluate_transfer_agg(tx_agg, "Texas")


merged = ca_results.merge(tx_results, on=["Lane","Class"], how="outer")


output_path = "/content/NY_Model_Transfer_ClassOnly_Aggregated.csv"
merged.to_csv(output_path, index=False)

print("‚úÖ Transferability results saved to:", output_path)
print(merged.to_string(index=False))

!ls /content

from docx import Document


text = """Lane Class  CA (RMSE)  CA (MAE)  CA (MAPE)  Texas (RMSE)  Texas (MAE)  Texas (MAPE)
1.0 4.0 3.53 3.53 19.08% 10.98 10.98 33.3%
1.0 5.0 9.88 9.88 91.81% 8.42 8.42 68.87%
... (continue pasting the rest of your table here)
"""

doc = Document()
doc.add_heading("Transferability Results ‚Äì NY Model", level=1)
doc.add_paragraph(text)
output_path = "/content/Transferability_Results.docx"
doc.save(output_path)

print(f" Word file saved at: {output_path}")

from docx import Document


text = """Lane Class  CA (RMSE)  CA (MAE)  CA (MAPE)  Texas (RMSE)  Texas (MAE)  Texas (MAPE)
1.0 4.0 3.53 3.53 19.08% 10.98 10.98 33.3%
1.0 5.0 9.88 9.88 91.81% 8.42 8.42 68.87%
1.0 6.0 13.21 13.21 63.81% 3.26 3.26 10.65%
1.0 7.0 12.66 12.66 36.41% 2.27 2.27 5.02%
"""

doc = Document()
doc.add_heading("Transferability Results ‚Äì NY Model", level=1)


lines = text.strip().split("\n")
headers = lines[0].split()
table = doc.add_table(rows=1, cols=len(headers))


hdr_cells = table.rows[0].cells
for i, h in enumerate(headers):
    hdr_cells[i].text = h


for line in lines[1:]:
    row_cells = table.add_row().cells
    for i, value in enumerate(line.split()):
        row_cells[i].text = value

output_path = "/content/Transferability_Results_Table.docx"
doc.save(output_path)
print(f"‚úÖ Formatted Word table saved at: {output_path}")

from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH

text = """Lane Class,CA (RMSE),CA (MAE),CA (MAPE),Texas (RMSE),Texas (MAE),Texas (MAPE)
1.0,4.0,3.53,3.53,19.08%,10.98,10.98,33.3%
1.0,5.0,9.88,9.88,91.81%,8.42,8.42,68.87%
1.0,6.0,13.21,13.21,63.81%,3.26,3.26,10.65%
1.0,7.0,12.66,12.66,36.41%,2.27,2.27,5.02%
"""


lines = [line.strip().split(",") for line in text.strip().split("\n")]
headers = lines[0]
data_rows = lines[1:]

num_cols = len(headers)
for i in range(len(data_rows)):
    if len(data_rows[i]) < num_cols:
        data_rows[i] += [""] * (num_cols - len(data_rows[i]))
    elif len(data_rows[i]) > num_cols:
        data_rows[i] = data_rows[i][:num_cols]

doc = Document()
doc.add_heading("Transferability Results ‚Äì NY Model", level=1)

table = doc.add_table(rows=1, cols=num_cols)
table.style = "Table Grid"

hdr_cells = table.rows[0].cells
for i, h in enumerate(headers):
    p = hdr_cells[i].paragraphs[0]
    run = p.add_run(h)
    run.bold = True
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER

for row_data in data_rows:
    row_cells = table.add_row().cells
    for i, value in enumerate(row_data):
        p = row_cells[i].paragraphs[0]
        p.add_run(value)
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER


output_path = "/content/Transferability_Results_Formatted.docx"
doc.save(output_path)
print(f"‚úÖ Clean formatted Word table saved at: {output_path}")

from google.colab import files

print("üìÅ Please choose your three CSV files:")
uploaded = files.upload()

import zipfile
import os

with zipfile.ZipFile("California_Combined_Ordered.zip", 'r') as zip_ref:
    zip_ref.extractall("/content")
    print("California file extracted!")


with zipfile.ZipFile("texas_master.zip", 'r') as zip_ref:
    zip_ref.extractall("/content")
    print("Texas file extracted!")


os.listdir("/content")

import pandas as pd


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
ca = pd.read_csv("/content/California_Combined_Ordered.csv")
tx = pd.read_csv("/content/texas_master.csv")


print("‚úÖ Files loaded successfully!\n")
print("üóΩ New York shape:", ny.shape)
print("üå¥ California shape:", ca.shape)
print("ü§† Texas shape:", tx.shape)


print("\nSample ‚Äî New York:")
print(ny.head(3))

print("\nSample ‚Äî California:")
print(ca.head(3))

print("\nSample ‚Äî Texas:")
print(tx.head(3))

import pandas as pd

def quick_preview(path):
    print(f"\nüìÇ Previewing: {path}")
    df = pd.read_csv(path, nrows=5)
    print("Columns:", list(df.columns))
    return df

ny = quick_preview("/content/NewYork_Combined_Ordered.csv")
ca = quick_preview("/content/California_Combined_Ordered.csv")
tx = quick_preview("/content/texas_master.csv")

import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error
import xgboost as xgb


feature = ['class']
target = 'gvw'


ny_train = ny.dropna(subset=[feature[0], target])
ny_train['class'] = pd.to_numeric(ny_train['class'], errors='coerce')
ny_train['gvw'] = pd.to_numeric(ny_train['gvw'], errors='coerce')

X_ny = ny_train[feature]
y_ny = ny_train[target]

model = xgboost = xgb.XGBRegressor(
    n_estimators=150,
    learning_rate=0.05,
    max_depth=4,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_ny, y_ny)


def compute_lane_class_metrics(model, df, state_name):
    records = []

    df2 = df.dropna(subset=['class', 'gvw'])
    df2['class'] = pd.to_numeric(df2['class'], errors='coerce')
    df2['gvw'] = pd.to_numeric(df2['gvw'], errors='coerce')

    for lane in sorted(df2['lane'].unique()):
        for cls in sorted(df2[df2['lane']==lane]['class'].unique()):
            subset = df2[(df2['lane'] == lane) & (df2['class'] == cls)]
            if len(subset) < 5:

                continue
            X_sub = subset[['class']]
            y_true = subset['gvw']
            y_pred = model.predict(X_sub)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))
            mae = mean_absolute_error(y_true, y_pred)
            mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
            records.append({
                'Lane': lane,
                'Class': cls,
                f'{state_name}_RMSE': rmse,
                f'{state_name}_MAE': mae,
                f'{state_name}_MAPE': mape
            })
    return pd.DataFrame(records)


df_ca = compute_lane_class_metrics(model, ca, 'CA')
df_tx = compute_lane_class_metrics(model, tx, 'TX')


df_all = pd.merge(df_ca, df_tx, on=['Lane','Class'], how='outer')


df_all = df_all.sort_values(['Lane','Class']).reset_index(drop=True)


for col in ['CA_MAPE', 'TX_MAPE']:
    df_all[col] = df_all[col].map(lambda x: f"{x:.2f}%" if pd.notnull(x) else "")


print(df_all.head(20))
df_all.to_csv("/content/Transfer_LaneClass_Results.csv", index=False)

import pandas as pd

df_rounded = df_all.copy()


metric_cols = [col for col in df_rounded.columns if col not in ['Lane', 'Class']]

for col in metric_cols:
    if 'MAPE' in col:

        df_rounded[col] = (
            df_rounded[col]
            .astype(str)
            .str.replace('%', '', regex=False)
            .apply(lambda x: f"{round(float(x), 2)}%" if x.strip() != '' and x.lower() != 'nan' else "")
        )
    else:
        df_rounded[col] = (
            df_rounded[col]
            .apply(lambda x: round(float(x), 2) if pd.notnull(x) else "")
        )

print(" Rounded successfully!")
print(df_rounded.head(10))


df_rounded.to_csv("/content/Transferability_Rounded.csv", index=False)
print("\nüìÑ Rounded table saved to: /content/Transferability_Rounded.csv")

from google.colab import files
files.download("/content/Transferability_Rounded.csv")

from google.colab import files
uploaded = files.upload()

import zipfile

zip_path = "/content/California_Combined_Ordered.zip"
extract_to = "/content/"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)
    print("California file extracted successfully.")

import os


print("üìÇ Extracted Files:")
print(os.listdir(extract_to))

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def run_xgb_one_feature(df, state_name):
    df.columns = df.columns.str.strip().str.lower()

    feature = "class"
    target = "gvw"
    results = []

    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X = class_data[[feature]]
            y = class_data[target]

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

            model = XGBRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.6,
                colsample_bytree=0.8,
                objective="reg:squarederror",
                random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
            r2 = r2_score(y_test, y_pred)

            results.append({
                "Lane": lane,
                "Class": cls,
                "RMSE": round(rmse, 2),
                "MAE": round(mae, 2),
                "MAPE (%)": round(mape, 2),
                "R2": round(r2, 3)
            })

    output_df = pd.DataFrame(results)
    file_path = f"/content/{state_name}_XGB_Results_OneFeature.csv"
    output_df.to_csv(file_path, index=False)
    print(f"Saved: {file_path}")
    return output_df

import zipfile
import os

zip_path = "/content/texas_master.zip"
extract_path = "/content/"

if os.path.exists(zip_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("‚úÖ Texas data extracted successfully!")
else:
    print("‚ö†Ô∏è texas_master.zip not found in /content/")

import os
print(os.listdir("/content"))

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


def run_xgb_one_feature(df, state_name):
    df.columns = df.columns.str.strip().str.lower()
    feature = "class"
    target = "gvw"
    results = []

    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X = class_data[[feature]]
            y = class_data[target]

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

            model = XGBRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.6,
                colsample_bytree=0.8,
                objective="reg:squarederror",
                random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
            r2 = r2_score(y_test, y_pred)

            results.append({
                "Lane": lane,
                "Class": cls,
                "RMSE": round(rmse, 2),
                "MAE": round(mae, 2),
                "MAPE (%)": round(mape, 2),
                "R2": round(r2, 3)
            })

    output_df = pd.DataFrame(results)
    file_path = f"/content/{state_name}_XGB_Results_OneFeature.csv"
    output_df.to_csv(file_path, index=False)
    print(f"‚úÖ Saved: {file_path}")
    return output_df


ca_df = pd.read_csv("/content/California_Combined_Ordered.csv")
ny_df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
tx_df = pd.read_csv("/content/texas_master.csv")


df_ca = run_xgb_one_feature(ca_df, "California")
df_ny = run_xgb_one_feature(ny_df, "NewYork")
df_tx = run_xgb_one_feature(tx_df, "Texas")

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def run_xgb_one_feature(file_path, state_name):
    df = pd.read_csv(file_path)
    df.columns = df.columns.str.strip().str.lower()

    feature = "class"
    target = "gvw"
    results = []

    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X = class_data[[feature]]
            y = class_data[target]

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

            model = XGBRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.6,
                colsample_bytree=0.8,
                objective="reg:squarederror",
                random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
            r2 = r2_score(y_test, y_pred)

            results.append({
                "Lane": lane,
                "Class": cls,
                "RMSE": round(rmse, 2),
                "MAE": round(mae, 2),
                "MAPE (%)": round(mape, 2),
                "R2": round(r2, 3)
            })

    output_df = pd.DataFrame(results)
    outpath = f"/content/{state_name}_XGB_Results_OneFeature.csv"
    output_df.to_csv(outpath, index=False)
    print(f"‚úÖ Saved: {outpath}")
    return output_df

df_ca = run_xgb_one_feature("/content/California_Combined_Ordered.csv", "California")

df_ny = run_xgb_one_feature("/content/NewYork_Combined_Ordered.csv", "NewYork")

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def run_xgb_one_feature(file_path, state_name):
    df = pd.read_csv(file_path)
    df.columns = df.columns.str.strip().str.lower()

    feature = "class"
    target = "gvw"
    results = []

    for lane in sorted(df["lane"].unique()):
        lane_data = df[df["lane"] == lane]
        for cls in sorted(lane_data["class"].unique()):
            class_data = lane_data[lane_data["class"] == cls]
            if len(class_data) < 50:
                continue

            X = class_data[[feature]]
            y = class_data[target]

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

            model = XGBRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.6,
                colsample_bytree=0.8,
                objective="reg:squarederror",
                random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
            r2 = r2_score(y_test, y_pred)

            results.append({
                "Lane": lane,
                "Class": cls,
                "RMSE": round(rmse, 2),
                "MAE": round(mae, 2),
                "MAPE (%)": round(mape, 2),
                "R2": round(r2, 3)
            })

    output_df = pd.DataFrame(results)
    outpath = f"/content/{state_name}_XGB_Results_OneFeature.csv"
    output_df.to_csv(outpath, index=False)
    print(f"‚úÖ Saved: {outpath}")
    return output_df

import pandas as pd

import pandas as pd

df = pd.read_csv("/content/texas_master.csv")
df.columns = df.columns.str.strip().str.lower()
print(df.columns.tolist())

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

def run_xgb_one_feature(df, state_name):
    df.columns = df.columns.str.strip().str.lower()


    df = df.rename(columns={"vehicle class": "class", "gvw": "gvw"})

    results = []

    lanes = sorted(df['lane'].unique())
    classes = sorted(df['class'].unique())

    for lane in lanes:
        for cls in classes:
            subset = df[(df['lane'] == lane) & (df['class'] == cls)]

            if len(subset) < 30:
                continue

            X = subset[['class']]
            y = subset['gvw']

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            model = XGBRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.6,
                colsample_bytree=0.8,
                random_state=42,
                verbosity=0
            )
            model.fit(X_train, y_train)

            y_pred = model.predict(X_test)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            mae = mean_absolute_error(y_test, y_pred)
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
            r2 = r2_score(y_test, y_pred)

            results.append({
                "Lane": lane,
                "Class": cls,
                "RMSE": round(rmse, 2),
                "MAE": round(mae, 2),
                "MAPE (%)": round(mape, 2),
                "R2": round(r2, 3)
            })

    output_df = pd.DataFrame(results)
    file_path = f"/content/{state_name}_XGB_Results_OneFeature.csv"
    output_df.to_csv(file_path, index=False)
    print(f"‚úÖ Saved: {file_path}")
    return output_df

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def run_xgb_one_feature(df, state_name):
    df.columns = df.columns.str.strip().str.lower()
    df = df.dropna(subset=["vehicle class", "gvw", "lane"])

    results = []
    for lane in sorted(df["lane"].unique()):
        for cls in sorted(df[df["lane"] == lane]["vehicle class"].unique()):
            subset = df[(df["lane"] == lane) & (df["vehicle class"] == cls)]

            if len(subset) < 50:
                continue

            X = subset[["vehicle class"]]
            y = subset["gvw"]

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            model = xgb.XGBRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.6,
                colsample_bytree=0.8,
                random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            rmse = mean_squared_error(y_test, y_pred, squared=False)
            mae = mean_absolute_error(y_test, y_pred)
            mape = (abs((y_test - y_pred) / y_test).mean()) * 100
            r2 = r2_score(y_test, y_pred)

            results.append({
                "Lane": lane,
                "Class": cls,
                "RMSE": round(rmse, 2),
                "MAE": round(mae, 2),
                "MAPE (%)": round(mape, 2),
                "R2": round(r2, 3)
            })

    output_df = pd.DataFrame(results)
    file_path = f"/content/{state_name}_XGB_Results_OneFeature.csv"
    output_df.to_csv(file_path, index=False)
    print(f"‚úÖ Saved: {file_path}")
    return output_df


tx_df = pd.read_csv("/content/texas_master.csv")
df_tx = run_xgb_one_feature(tx_df, "Texas")



from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import matplotlib.pyplot as plt


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")

print("‚úÖ Dataset successfully loaded!")
print("Shape:", df.shape)
print("Columns:", list(df.columns))
print("\nData types before conversion:\n", df.dtypes)
print("\n")


for col in df.select_dtypes(include=['object']).columns:
    df[col] = df[col].astype('category').cat.codes

print("‚úÖ All object columns converted to numeric codes.\n")


X = df.drop(columns=['gvw'])
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


model = xgb.XGBRegressor(
    n_estimators=150,
    learning_rate=0.05,
    max_depth=4,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)


y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


results = pd.DataFrame({
    'Metric': ['RMSE (kN)', 'MAE (kN)', 'MAPE (%)', 'R¬≤'],
    'Value': [round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3)]
})

print("üìä Model Performance on New York Dataset (XGBoost):\n")
print(results.to_string(index=False))


plt.figure(figsize=(8, 6))
xgb.plot_importance(model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for GVW Prediction (New York)", fontsize=13)
plt.tight_layout()
plt.show()


results.to_csv("/content/NewYork_XGBoost_Results.csv", index=False)
print("\n‚úÖ Results saved as: NewYork_XGBoost_Results.csv")

import zipfile
import os


zip_path = "/content/California_Combined_Ordered.zip"


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/")
    print("‚úÖ California file extracted!")


print("\nExtracted files:")
print(os.listdir("/content/"))

from google.colab import files
uploaded = files.upload()

import zipfile, os


zip_path = "/content/texas_master.zip"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content")

print("‚úÖ Texas file extracted successfully!\nExtracted files:")
print(os.listdir("/content"))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


df = pd.read_csv("/content/texas_master.csv", nrows=500000, low_memory=False)
print("‚úÖ Loaded subset:", df.shape)
print("Columns:", list(df.columns))


drop_cols = [c for c in ['Dir', 'month_name'] if c in df.columns]
df = df.drop(columns=drop_cols)
print("Dropped columns:", drop_cols)


df.rename(columns={
    'vehicle class': 'class',
    'number of axle': 'axles'
}, inplace=True)


for col in df.select_dtypes(include=['float64', 'int64']).columns:
    df[col] = pd.to_numeric(df[col], downcast='float')


X = df.drop(columns=['gvw'])
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


model = xgb.XGBRegressor(
    n_estimators=80,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.7,
    colsample_bytree=0.8,
    tree_method='hist',
    random_state=42
)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae  = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2   = r2_score(y_test, y_pred)

results = pd.DataFrame({
    'Metric': ['RMSE (kN)', 'MAE (kN)', 'MAPE (%)', 'R¬≤'],
    'Value': [round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3)]
})
print("\nüìä Model Performance (Texas subset):\n")
print(results.to_string(index=False))


plt.figure(figsize=(8, 6))
xgb.plot_importance(model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for GVW Prediction (Texas subset)", fontsize=13)
plt.tight_layout()
plt.show()


results.to_csv("/content/Texas_XGBoost_Performance_Cleaned.csv", index=False)
print("\n‚úÖ Results saved as: /content/Texas_XGBoost_Performance_Cleaned.csv")

from google.colab import files
uploaded = files.upload()

import os


print("üìÅ Files currently in /content:")
for f in os.listdir("/content"):
    print(f)

common_features = ['year', 'month', 'day', 'hour', 'lane', 'class', 'num_axles', 'gvw']


ny = ny[[c for c in common_features if c in ny.columns]]
ca = ca[[c for c in common_features if c in ca.columns]]
tx = tx[[c for c in common_features if c in tx.columns]]


print("\n‚úÖ Final Columns Alignment:")
print("New York:", list(ny.columns))
print("California:", list(ca.columns))
print("Texas:", list(tx.columns))


X_ny = ny.drop(columns=['gvw'])
y_ny = ny['gvw']
X_train, X_test, y_train, y_test = train_test_split(X_ny, y_ny, test_size=0.3, random_state=42)

model = xgb.XGBRegressor(
    n_estimators=80,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.7,
    colsample_bytree=0.8,
    tree_method='hist',
    random_state=42
)
model.fit(X_train, y_train, verbose=False)

y_pred_ny = model.predict(X_test)
rmse_ny = np.sqrt(mean_squared_error(y_test, y_pred_ny))
mae_ny = mean_absolute_error(y_test, y_pred_ny)
mape_ny = np.mean(np.abs((y_test - y_pred_ny) / y_test)) * 100
r2_ny = r2_score(y_test, y_pred_ny)

print(f"\nüìä New York Base Model (Unified Features):")
print(f"RMSE={rmse_ny:.2f}, MAE={mae_ny:.2f}, MAPE={mape_ny:.2f}%, R¬≤={r2_ny:.3f}")


def evaluate_transfer(df, name):
    X_t = df.drop(columns=['gvw'])
    y_t = df['gvw']
    y_pred = model.predict(X_t)
    rmse = np.sqrt(mean_squared_error(y_t, y_pred))
    mae = mean_absolute_error(y_t, y_pred)
    mape = np.mean(np.abs((y_t - y_pred) / y_t)) * 100
    r2 = r2_score(y_t, y_pred)
    TI = 1 - ((rmse - rmse_ny) / rmse_ny)
    return [name, round(rmse, 2), round(mae, 2), round(mape, 2), round(r2, 3), round(TI, 3)]

results = [
    ["New York (Base)", round(rmse_ny, 2), round(mae_ny, 2), round(mape_ny, 2), round(r2_ny, 3), 1.000],
    evaluate_transfer(ca, "California"),
    evaluate_transfer(tx, "Texas")
]

results_df = pd.DataFrame(results, columns=["Dataset", "RMSE (kN)", "MAE (kN)", "MAPE (%)", "R¬≤", "Transferability Index"])

print("\nüìà Transferability Results (Unified Features):\n")
print(results_df.to_string(index=False))


output_path = "/content/Transferability_Aligned_Final.csv"
results_df.to_csv(output_path, index=False)
print(f"\n‚úÖ Results saved to: {output_path}")

import os
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


ny_path = "/content/NewYork_Combined_Ordered.csv"
ca_path = "/content/California_Combined_Ordered.csv"
tx_path = "/content/texas_master.csv"


def load_and_standardize(path, name, sample_size=None, chunksize=None):
    print(f"\nüì• Loading {name}...")

    if chunksize:
        chunks = []
        for chunk in pd.read_csv(path, chunksize=chunksize, low_memory=True):
            chunks.append(chunk.sample(min(len(chunk), int(chunksize * 0.05)), random_state=42))
            if sum(len(c) for c in chunks) >= sample_size:
                break
        df = pd.concat(chunks, ignore_index=True)
    else:
        df = pd.read_csv(path, low_memory=True)
        if sample_size:
            df = df.sample(min(len(df), sample_size), random_state=42)


    df.columns = df.columns.str.lower().str.strip()
    rename_map = {
        'vehicle class': 'class',
        'veh_class': 'class',
        'classid': 'class',
        'number of axle': 'num_axles',
        'axles': 'num_axles',
        'speed(km/h)': 'speed',
        'avg_speed': 'speed',
        'spd': 'speed',
    }
    df.rename(columns=rename_map, inplace=True)


    keep_cols = ['year','month','day','hour','lane','class','speed','num_axles','gvw']
    available_cols = [c for c in keep_cols if c in df.columns]
    df = df[available_cols]

    print(f"‚úÖ {name} loaded ‚Üí shape {df.shape}, cols: {list(df.columns)}")
    return df


ny = load_and_standardize(ny_path, "New York", sample_size=300000)
ca = load_and_standardize(ca_path, "California", sample_size=200000)

import os
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


ny_path = "/content/NewYork_Combined_Ordered.csv"
ca_path = "/content/California_Combined_Ordered.csv"
tx_path = "/content/texas_master.csv"


def load_and_standardize(path, name):
    df = pd.read_csv(path, low_memory=True)
    df.columns = df.columns.str.lower().str.strip()

    rename_map = {
        'vehicle class': 'class',
        'veh_class': 'class',
        'classid': 'class',
        'num_axles': 'num_axles',
        'number of axle': 'num_axles',
        'axles': 'num_axles',
        'speed(km/h)': 'speed',
        'spd': 'speed',
        'avg_speed': 'speed',
        'dir': 'dir'
    }
    df.rename(columns=rename_map, inplace=True)


    keep_cols = ['year','month','day','hour','lane','class','speed','num_axles','gvw']
    available_cols = [c for c in keep_cols if c in df.columns]
    df = df[available_cols]

    print(f"‚úÖ {name} loaded: {df.shape} columns ‚Üí {df.columns.tolist()}")
    return df


ny = load_and_standardize(ny_path, "New York")
ca = load_and_standardize(ca_path, "California")
tx = load_and_standardize(tx_path, "Texas")


ny = ny.sample(min(len(ny), 300000), random_state=42)
ca = ca.sample(min(len(ca), 200000), random_state=42)
tx = tx.sample(min(len(tx), 200000), random_state=42)


for df in [ny, ca, tx]:
    for col in df.select_dtypes(include=['float64','int64']).columns:
        df[col] = pd.to_numeric(df[col], downcast='float')


X_ny = ny.drop(columns=['gvw'])
y_ny = ny['gvw']

X_train, X_test, y_train, y_test = train_test_split(X_ny, y_ny, test_size=0.3, random_state=42)

model = xgb.XGBRegressor(
    n_estimators=80,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.7,
    colsample_bytree=0.8,
    tree_method='hist',
    random_state=42
)
model.fit(X_train, y_train, verbose=False)


y_pred_ny = model.predict(X_test)
rmse_ny = np.sqrt(mean_squared_error(y_test, y_pred_ny))
mae_ny  = mean_absolute_error(y_test, y_pred_ny)
mape_ny = np.mean(np.abs((y_test - y_pred_ny) / y_test)) * 100
r2_ny   = r2_score(y_test, y_pred_ny)

print(f"\nüìä New York Base Model:")
print(f"RMSE={rmse_ny:.2f}, MAE={mae_ny:.2f}, MAPE={mape_ny:.2f}%, R¬≤={r2_ny:.3f}")


def evaluate_transfer(df, name):
    X_t = df.drop(columns=['gvw'])
    y_t = df['gvw']
    y_pred = model.predict(X_t)
    rmse = np.sqrt(mean_squared_error(y_t, y_pred))
    mae  = mean_absolute_error(y_t, y_pred)
    mape = np.mean(np.abs((y_t - y_pred) / y_t)) * 100
    r2   = r2_score(y_t, y_pred)
    TI   = 1 - ((rmse - rmse_ny) / rmse_ny)
    return [name, round(rmse,2), round(mae,2), round(mape,2), round(r2,3), round(TI,3)]


results = [
    ["New York (Base)", round(rmse_ny,2), round(mae_ny,2), round(mape_ny,2), round(r2_ny,3), 1.000],
    evaluate_transfer(ca, "California"),
    evaluate_transfer(tx, "Texas")
]

results_df = pd.DataFrame(results, columns=["Dataset","RMSE (kN)","MAE (kN)","MAPE (%)","R¬≤","Transferability Index"])

print("\nüìà Transferability Results:\n")
print(results_df.to_string(index=False))


out_path = "/content/Transferability_NY_CA_TX_Flexible.csv"
results_df.to_csv(out_path, index=False)
print(f"\n‚úÖ Results saved to: {out_path}")

from google.colab import files; uploaded = files.upload()

from google.colab import files; uploaded = files.upload()

import zipfile
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


zip_path = "/content/California_Combined_Ordered.zip"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content")
print("‚úÖ California file extracted successfully!")


ca = pd.read_csv("/content/California_Combined_Ordered.csv")
print("‚úÖ California dataset loaded!")
print("Shape:", ca.shape)
print("Columns:", list(ca.columns))


X = ca[['class', 'num_axles']]
y = ca['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
print(f"\nData split -> Train: {len(X_train)} | Test: {len(X_test)}")


model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.6,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


print("\nüìä Model Performance using only 'class' and 'num_axles' (California):")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.4, color='steelblue', label='Predicted Points')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r-', lw=2, label='Perfect Prediction Line')
plt.title("Actual vs Predicted GVW using Class and Num_Axles (California)")
plt.xlabel("Actual GVW (kN)")
plt.ylabel("Predicted GVW (kN)")
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
df = pd.read_csv("/content/NewYork_Combined_Ordered.csv")
df.head()

from google.colab import files; uploaded = files.upload()

import zipfile, os


zip_path = "/content/texas_master.zip"


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content")


files = [f for f in os.listdir("/content") if f.endswith('.csv')]
print("‚úÖ Extraction complete!")
print("Extracted files:", files)

import pandas as pd


df = pd.read_csv("/content/texas_master.csv", low_memory=False)


print("‚úÖ Texas dataset loaded successfully!")
print(f"Shape: {df.shape}")
print("\nColumns available:")
print(df.columns.tolist())


print("\nSample rows:")
print(df.head())

import pandas as pd


df = pd.read_csv("/content/texas_master.csv", nrows=5)

print("‚úÖ File loaded (preview only)")
print("Columns:", df.columns.tolist())
print("\nSample data:")
print(df.head())

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor
import numpy as np


use_cols = ['vehicle class', 'number of axle', 'gvw']
df = pd.read_csv("/content/texas_master.csv", usecols=use_cols, low_memory=False)

print("‚úÖ Texas dataset loaded successfully!")
print("Shape:", df.shape)
print("Columns:", df.columns.tolist())


df = df.dropna(subset=['vehicle class', 'number of axle', 'gvw'])


df = df.rename(columns={'vehicle class': 'class', 'number of axle': 'num_axles'})


df = df.sample(n=300000, random_state=42)
print("‚úÖ Sampled:", df.shape)


X = df[['class', 'num_axles']]
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.6,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)


y_pred = model.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)

print("\nüìä XGBoost Model Performance (Texas Dataset)")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")

import matplotlib.pyplot as plt
import numpy as np


plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.4, edgecolors='k')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2)
plt.title("Predicted vs Actual GVW (Texas Dataset)\nXGBoost using Class & Num_Axles", fontsize=12)
plt.xlabel("Actual GVW (kN)")
plt.ylabel("Predicted GVW (kN)")
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.4, edgecolors='k')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r-', lw=2)
plt.title("Predicted vs Actual GVW (Texas Dataset)\nXGBoost using Class & Num_Axles", fontsize=12)
plt.xlabel("Actual GVW (kN)")
plt.ylabel("Predicted GVW (kN)")
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

import pandas as pd
import numpy as np
from sklearn.m odel_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
import math

ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])


tx = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class','number of axle','gvw'])
tx.rename(columns={'vehicle class':'class', 'number of axle':'num_axles'}, inplace=True)

print("‚úÖ Datasets loaded successfully:")
print(f"New York: {ny.shape}, California: {ca.shape}, Texas: {tx.shape}")


for df in [ny, ca, tx]:
    df.dropna(inplace=True)
    df = df[df['gvw'] > 0]


X_ny = ny[['class', 'num_axles']]
y_ny = ny['gvw']

X_train, X_test, y_train, y_test = train_test_split(X_ny, y_ny, test_size=0.3, random_state=42)


model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.6,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_train, y_train)


y_pred_ny = model.predict(X_test)
rmse_ny = math.sqrt(mean_squared_error(y_test, y_pred_ny))
mae_ny = mean_absolute_error(y_test, y_pred_ny)
mape_ny = np.mean(np.abs((y_test - y_pred_ny) / y_test)) * 100
r2_ny = r2_score(y_test, y_pred_ny)

print(f"\nüìä New York (Base Model):")
print(f"RMSE = {rmse_ny:.2f}, MAE = {mae_ny:.2f}, MAPE = {mape_ny:.2f}%, R¬≤ = {r2_ny:.3f}")


def evaluate_transfer(df, name):
    X = df[['class', 'num_axles']]
    y = df['gvw']
    y_pred = model.predict(X)
    rmse = math.sqrt(mean_squared_error(y, y_pred))
    mae = mean_absolute_error(y, y_pred)
    mape = np.mean(np.abs((y - y_pred) / y)) * 100
    r2 = r2_score(y, y_pred)
    ti = r2 / r2_ny
    print(f"\nüåç {name} Transfer Results:")
    print(f"RMSE = {rmse:.2f}, MAE = {mae:.2f}, MAPE = {mape:.2f}%, R¬≤ = {r2:.3f}, TI = {ti:.3f}")
    return [name, round(rmse,2), round(mae,2), round(mape,2), round(r2,3), round(ti,3)]


results = [
    ["New York (Base)", round(rmse_ny,2), round(mae_ny,2), round(mape_ny,2), round(r2_ny,3), 1.000],
    evaluate_transfer(ca, "California"),
    evaluate_transfer(tx, "Texas")
]


df_results = pd.DataFrame(results, columns=["Dataset", "RMSE (kN)", "MAE (kN)", "MAPE (%)", "R¬≤", "Transferability Index"])
print("\n‚úÖ Transferability Results (Class + Num_Axles):")
print(df_results)


df_results.to_csv("/content/Transferability_Class_NumAxles.csv", index=False)
print("\nüíæ Results saved to: /content/Transferability_Class_NumAxles.csv")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb

ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
tx = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class','number of axle','gvw'])
tx.rename(columns={'vehicle class':'class', 'number of axle':'num_axles'}, inplace=True)

X_ny = ny[['class','num_axles']]
y_ny = ny['gvw']
model = xgb.XGBRegressor(
    n_estimators=100, learning_rate=0.05, max_depth=3,
    subsample=0.6, colsample_bytree=0.8, random_state=42
)
model.fit(X_ny, y_ny)


def plot_transfer_safe(df, name, sample_size=10000):
    X = df[['class', 'num_axles']]
    y_true = df['gvw']
    y_pred = model.predict(X)

    if len(df) > sample_size:
        sample_idx = np.random.choice(len(df), sample_size, replace=False)
        y_true = y_true.iloc[sample_idx]
        y_pred = y_pred[sample_idx]

    plt.figure(figsize=(6,6))
    plt.scatter(y_true, y_pred, alpha=0.4, s=8, label='Predicted')
    max_val = max(y_true.max(), y_pred.max())
    plt.plot([0, max_val], [0, max_val], 'r-', linewidth=2, label='Perfect Prediction')
    plt.xlabel("Actual GVW (kN)")
    plt.ylabel("Predicted GVW (kN)")
    plt.title(f"Predicted vs Actual GVW ({name})\nNY-Trained XGBoost (Class + Num_Axles)")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.show()


plot_transfer_safe(ca, "California", sample_size=10000)
plot_transfer_safe(tx, "Texas", sample_size=10000)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
tx = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class','number of axle','gvw'])
tx.rename(columns={'vehicle class':'class', 'number of axle':'num_axles'}, inplace=True)


X_ny = ny[['class','num_axles']]
y_ny = ny['gvw']

model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.6,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_ny, y_ny)


def plot_transfer_and_save(df, name, filename, sample_size=10000):
    X = df[['class', 'num_axles']]
    y_true = df['gvw']
    y_pred = model.predict(X)


    if len(df) > sample_size:
        idx = np.random.choice(len(df), sample_size, replace=False)
        y_true = y_true.iloc[idx]
        y_pred = y_pred[idx]

    plt.figure(figsize=(7,7))
    plt.scatter(y_true, y_pred, alpha=0.35, s=10, label='Predicted Points', color='dodgerblue')
    max_val = max(y_true.max(), y_pred.max())
    plt.plot([0, max_val], [0, max_val], 'r-', linewidth=2, label='Perfect Prediction')
    plt.xlabel("Actual GVW (kN)", fontsize=12)
    plt.ylabel("Predicted GVW (kN)", fontsize=12)
    plt.title(f"Predicted vs Actual GVW ({name})\nNY-Trained XGBoost (Class + Num_Axles)", fontsize=13)
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.savefig(f"/content/{filename}", dpi=400)
    plt.show()
    print(f" Saved: /content/{filename}")

plot_transfer_and_save(ca, "California", "California_Transferability.png")
plot_transfer_and_save(tx, "Texas", "Texas_Transferability.png")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])


X = df[['class', 'num_axles']]
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


rf = RandomForestRegressor(
    n_estimators=200,
    max_depth=8,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)


y_pred = rf.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


print("üå≤ Random Forest Model Performance (New York Dataset)")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])


X = ca[['class', 'num_axles']]
y = ca['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


rf_ca = RandomForestRegressor(
    n_estimators=200,
    max_depth=8,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf_ca.fit(X_train, y_train)


y_pred = rf_ca.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


print("üå≤ Random Forest Model Performance (California Dataset)")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


chunk_size = 500000
sample_frac = 0.05

data_chunks = []
use_cols = ['vehicle class', 'number of axle', 'gvw']

for chunk in pd.read_csv("/content/texas_master.csv", usecols=use_cols, chunksize=chunk_size, low_memory=True):
    data_chunks.append(chunk.sample(frac=sample_frac, random_state=42))

df = pd.concat(data_chunks, ignore_index=True)
df.rename(columns={'vehicle class':'class', 'number of axle':'num_axles'}, inplace=True)

print(f"‚úÖ Loaded sample from large dataset: {df.shape[0]:,} rows")
print("Columns:", df.columns.tolist())
print(df.head())


X = df[['class', 'num_axles']]
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


rf_tx = RandomForestRegressor(
    n_estimators=200,
    max_depth=8,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf_tx.fit(X_train, y_train)


y_pred = rf_tx.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


print("\nüå≤ Random Forest Model Performance (Texas Dataset)")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])
tx = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class','number of axle','gvw'])
tx.rename(columns={'vehicle class':'class', 'number of axle':'num_axles'}, inplace=True)

print("‚úÖ Datasets loaded successfully:")
print(f"New York: {ny.shape}, California: {ca.shape}, Texas: {tx.shape}")


X_ny = ny[['class', 'num_axles']]
y_ny = ny['gvw']

X_train, X_test, y_train, y_test = train_test_split(X_ny, y_ny, test_size=0.3, random_state=42)

rf_ny = RandomForestRegressor(
    n_estimators=200,
    max_depth=8,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf_ny.fit(X_train, y_train)


y_pred_ny = rf_ny.predict(X_test)
rmse_ny = np.sqrt(mean_squared_error(y_test, y_pred_ny))
mae_ny = mean_absolute_error(y_test, y_pred_ny)
mape_ny = np.mean(np.abs((y_test - y_pred_ny) / y_test)) * 100
r2_ny = r2_score(y_test, y_pred_ny)


def evaluate_transfer(df, name):
    X = df[['class', 'num_axles']]
    y_true = df['gvw']
    y_pred = rf_ny.predict(X)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2 = r2_score(y_true, y_pred)
    transfer_index = r2 / r2_ny if r2_ny != 0 else np.nan
    print(f"\nüìä {name} Prediction Completed")
    return [name, rmse, mae, mape, r2, transfer_index]


results = [
    ["New York (Base)", rmse_ny, mae_ny, mape_ny, r2_ny, 1.000],
    evaluate_transfer(ca, "California"),
    evaluate_transfer(tx, "Texas")
]


df_results = pd.DataFrame(results, columns=["Dataset","RMSE (kN)","MAE (kN)","MAPE (%)","R¬≤","Transferability Index"])
df_results = df_results.round(3)
df_results.to_csv("/content/RandomForest_Transferability.csv", index=False)

print("\n‚úÖ Transferability Results:")
print(df_results)
print("\nResults saved to: /content/RandomForest_Transferability.csv")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])


X = df[['class', 'num_axles']]
y = df['gvw']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


xgb_model = XGBRegressor(
    n_estimators=100, learning_rate=0.05, max_depth=3,
    subsample=0.6, colsample_bytree=0.8, random_state=42
)
rf_model = RandomForestRegressor(
    n_estimators=200, max_depth=8, min_samples_split=5,
    min_samples_leaf=2, random_state=42, n_jobs=-1
)

xgb_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)


y_pred_xgb = xgb_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)


plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred_xgb, color='royalblue', alpha=0.5, label='XGBoost Predictions')
plt.scatter(y_test, y_pred_rf, color='darkorange', alpha=0.5, label='Random Forest Predictions')


min_val, max_val = y_test.min(), y_test.max()
plt.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--', linewidth=2, label='Perfect Fit (y=x)')

plt.title("Comparison of XGBoost and Random Forest Predictions ‚Äì New York", fontsize=13)
plt.xlabel("Actual GVW (kN)", fontsize=12)
plt.ylabel("Predicted GVW (kN)", fontsize=12)
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor


df = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])


X = df[['class', 'num_axles']]
y = df['gvw']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

=
xgb_model = XGBRegressor(
    n_estimators=100, learning_rate=0.05, max_depth=3,
    subsample=0.6, colsample_bytree=0.8, random_state=42
)
rf_model = RandomForestRegressor(
    n_estimators=200, max_depth=8, min_samples_split=5,
    min_samples_leaf=2, random_state=42, n_jobs=-1
)

xgb_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)


y_pred_xgb = xgb_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)


def model_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    return rmse, r2

rmse_xgb, r2_xgb = model_metrics(y_test, y_pred_xgb)
rmse_rf, r2_rf = model_metrics(y_test, y_pred_rf)


plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred_xgb, color='royalblue', alpha=0.5, label='XGBoost Predictions')
plt.scatter(y_test, y_pred_rf, color='darkorange', alpha=0.5, label='Random Forest Predictions')

min_val, max_val = y_test.min(), y_test.max()
plt.plot([min_val, max_val], [min_val, max_val],
         color='black', linestyle='-', linewidth=2, label='Perfect Fit (y=x)')


plt.title("Comparison of XGBoost and Random Forest Predictions ‚Äì New York", fontsize=13)
plt.xlabel("Actual GVW (kN)", fontsize=12)
plt.ylabel("Predicted GVW (kN)", fontsize=12)
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)


plt.text(min_val + 10, max_val - 25,
         f"XGBoost ‚Üí RMSE: {rmse_xgb:.2f} kN, R¬≤: {r2_xgb:.3f}\n"
         f"Random Forest ‚Üí RMSE: {rmse_rf:.2f} kN, R¬≤: {r2_rf:.3f}",
         fontsize=10, bbox=dict(facecolor='white', alpha=0.7))

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor


df = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'])


X = df[['class', 'num_axles']]
y = df['gvw']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


xgb_model = XGBRegressor(
    n_estimators=100, learning_rate=0.05, max_depth=3,
    subsample=0.6, colsample_bytree=0.8, random_state=42
)
rf_model = RandomForestRegressor(
    n_estimators=200, max_depth=8, min_samples_split=5,
    min_samples_leaf=2, random_state=42, n_jobs=-1
)

xgb_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)


y_pred_xgb = xgb_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)


def model_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    return rmse, r2

rmse_xgb, r2_xgb = model_metrics(y_test, y_pred_xgb)
rmse_rf, r2_rf = model_metrics(y_test, y_pred_rf)


plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred_xgb, color='royalblue', alpha=0.5, label='XGBoost Predictions')
plt.scatter(y_test, y_pred_rf, color='darkorange', alpha=0.5, label='Random Forest Predictions')


min_val, max_val = y_test.min(), y_test.max()
plt.plot([min_val, max_val], [min_val, max_val],
         color='black', linestyle='-', linewidth=2, label='Perfect Fit (y=x)')


plt.title("Comparison of XGBoost and Random Forest Predictions ‚Äì California", fontsize=13)
plt.xlabel("Actual GVW (kN)", fontsize=12)
plt.ylabel("Predicted GVW (kN)", fontsize=12)
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)


plt.text(min_val + 10, max_val - 25,
         f"XGBoost ‚Üí RMSE: {rmse_xgb:.2f} kN, R¬≤: {r2_xgb:.3f}\n"
         f"Random Forest ‚Üí RMSE: {rmse_rf:.2f} kN, R¬≤: {r2_rf:.3f}",
         fontsize=10, bbox=dict(facecolor='white', alpha=0.7))

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv",
                 usecols=['class','num_axles','gvw'], low_memory=True)
ca = pd.read_csv("/content/California_Combined_Ordered.csv",
                 usecols=['class','num_axles','gvw'], low_memory=True)


ny.columns = ['class','num_axles','gvw']
ca.columns = ['class','num_axles','gvw']


X_ny = ny[['class','num_axles']]
y_ny = ny['gvw']

xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=3,
                         subsample=0.6, colsample_bytree=0.8, random_state=42)
rf_model  = RandomForestRegressor(n_estimators=200, max_depth=8,
                                  min_samples_leaf=2, random_state=42, n_jobs=-1)

xgb_model.fit(X_ny, y_ny)
rf_model.fit(X_ny, y_ny)


X_ca = ca[['class','num_axles']]
y_ca = ca['gvw']

y_pred_xgb_ca = xgb_model.predict(X_ca)
y_pred_rf_ca  = rf_model.predict(X_ca)


def calc_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae  = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2   = r2_score(y_true, y_pred)
    return rmse, mae, mape, r2

m_xgb_ca = calc_metrics(y_ca, y_pred_xgb_ca)
m_rf_ca  = calc_metrics(y_ca, y_pred_rf_ca)

print("California ‚Äì XGBoost ‚Üí RMSE: {:.2f}, MAE: {:.2f}, MAPE: {:.2f}%, R¬≤: {:.3f}"
      .format(*m_xgb_ca))
print("California ‚Äì RandomForest ‚Üí RMSE: {:.2f}, MAE: {:.2f}, MAPE: {:.2f}%, R¬≤: {:.3f}"
      .format(*m_rf_ca))


plt.figure(figsize=(6,6))
plt.scatter(y_ca, y_pred_xgb_ca, color='blue', alpha=0.4, label="XGBoost Predictions")
mn, mx = min(y_ca.min(), y_pred_xgb_ca.min()), max(y_ca.max(), y_pred_xgb_ca.max())
plt.plot([mn,mx],[mn,mx], color='black', linestyle='-', linewidth=2, label="Perfect Fit (y=x)")
plt.title("Transferability ‚Äì California: XGBoost", fontsize=12)
plt.xlabel("Actual GVW (kN)")
plt.ylabel("Predicted GVW (kN)")
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.tight_layout()
plt.show()


plt.figure(figsize=(6,6))
plt.scatter(y_ca, y_pred_rf_ca, color='orange', alpha=0.4, label="Random Forest Predictions")
mn, mx = min(y_ca.min(), y_pred_rf_ca.min()), max(y_ca.max(), y_pred_rf_ca.max())
plt.plot([mn,mx],[mn,mx], color='black', linestyle='-', linewidth=2, label="Perfect Fit (y=x)")
plt.title("Transferability ‚Äì California: Random Forest", fontsize=12)
plt.xlabel("Actual GVW (kN)")
plt.ylabel("Predicted GVW (kN)")
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


df = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class', 'number of axle', 'gvw'], low_memory=True)
df.columns = ['class', 'num_axles', 'gvw']


df_sample = df.sample(n=500000, random_state=42) if len(df) > 500000 else df
print(f"Texas subset shape: {df_sample.shape}")


X = df_sample[['class', 'num_axles']]
y = df_sample['gvw']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


lr = LinearRegression()
lr.fit(X_train, y_train)


y_pred = lr.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)

print(f"üìä Linear Regression Performance (Texas Dataset):")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")


plt.figure(figsize=(7,7))
plt.scatter(y_test, y_pred, color='mediumseagreen', alpha=0.4, label='Linear Regression Predictions')
min_val, max_val = y_test.min(), y_test.max()
plt.plot([min_val, max_val], [min_val, max_val],
         color='black', linestyle='-', linewidth=2, label='Perfect Fit (y=x)')
plt.title("Linear Regression Model ‚Äì Texas Dataset", fontsize=13)
plt.xlabel("Actual GVW (kN)", fontsize=12)
plt.ylabel("Predicted GVW (kN)", fontsize=12)
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


ny = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'], low_memory=True)
ca = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'], low_memory=True)
tx = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class','number of axle','gvw'], low_memory=True)


ny.columns = ['class','num_axles','gvw']
ca.columns = ['class','num_axles','gvw']
tx.columns = ['class','num_axles','gvw']

print("‚úÖ Datasets loaded and standardized!")

X_train = ny[['class','num_axles']]
y_train = ny['gvw']


def evaluate_transfer(df, name, model, r2_base):
    X_test = df[['class','num_axles']]
    y_test = df['gvw']
    y_pred = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    r2 = r2_score(y_test, y_pred)
    transfer_index = r2 / r2_base if r2_base != 0 else 0

    print(f"\nüìä {name} Transfer Results:")
    print(f"RMSE: {rmse:.3f} kN")
    print(f"MAE: {mae:.3f} kN")
    print(f"MAPE: {mape:.2f}%")
    print(f"R¬≤: {r2:.3f}")
    print(f"Transferability Index: {transfer_index:.3f}")

    return [name, rmse, mae, mape, r2, transfer_index]


lr = LinearRegression()
lr.fit(X_train, y_train)

y_pred_ny = lr.predict(X_train)
rmse_ny = np.sqrt(mean_squared_error(y_train, y_pred_ny))
mae_ny = mean_absolute_error(y_train, y_pred_ny)
mape_ny = np.mean(np.abs((y_train - y_pred_ny) / y_train)) * 100
r2_ny = r2_score(y_train, y_pred_ny)


results = []
results.append(["New York (Base)", rmse_ny, mae_ny, mape_ny, r2_ny, 1.0])
results.append(evaluate_transfer(ca, "California", lr, r2_ny))
results.append(evaluate_transfer(tx, "Texas", lr, r2_ny))


import pandas as pd
transfer_results = pd.DataFrame(results, columns=["Dataset","RMSE (kN)","MAE (kN)","MAPE (%)","R¬≤","Transferability Index"])

print("\n‚úÖ Linear Regression Transferability Results:")
print(transfer_results)

transfer_results.to_csv("/content/LinearRegression_Transferability.csv", index=False)
print("\nüíæ Results saved as 'LinearRegression_Transferability.csv'")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


ny  = pd.read_csv("/content/NewYork_Combined_Ordered.csv", usecols=['class','num_axles','gvw'], low_memory=True).rename(columns={'class':'class','num_axles':'num_axles','gvw':'gvw'})
ca  = pd.read_csv("/content/California_Combined_Ordered.csv", usecols=['class','num_axles','gvw'], low_memory=True).rename(columns={'class':'class','num_axles':'num_axles','gvw':'gvw'})
tx  = pd.read_csv("/content/texas_master.csv", usecols=['vehicle class','number of axle','gvw'], low_memory=True).rename(columns={'vehicle class':'class','number of axle':'num_axles','gvw':'gvw'})


X_ny = ny[['class','num_axles']]
y_ny = ny['gvw']


lr = LinearRegression()
lr.fit(X_ny, y_ny)


rf = RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_leaf=2, random_state=42, n_jobs=-1)
rf.fit(X_ny, y_ny)

xgb = XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=3, subsample=0.6, colsample_bytree=0.8, random_state=42)
xgb.fit(X_ny, y_ny)


def pred_and_metrics(model, df, label):
    X = df[['class','num_axles']]
    y = df['gvw']
    y_pred = model.predict(X)
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    mae  = mean_absolute_error(y, y_pred)
    mape = np.mean(np.abs((y - y_pred) / y)) * 100
    r2   = r2_score(y, y_pred)
    print(f"{label}: RMSE={rmse:.2f}, MAE={mae:.2f}, MAPE={mape:.2f}%, R¬≤={r2:.3f}")
    return y, y_pred


fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)

for ax, (df, name) in zip(axes, [(ca, "California"), (tx, "Texas")]):
    y_true_lr, y_pred_lr = pred_and_metrics(lr, df,    f"Linear-Regression ‚Üí {name}")
    y_true_rf, y_pred_rf = pred_and_metrics(rf, df,    f"Random-Forest ‚Üí {name}")
    y_true_xgb, y_pred_xgb = pred_and_metrics(xgb, df, f"XGBoost ‚Üí {name}")

    ax.scatter(y_true_lr, y_pred_lr, color='darkorange', alpha=0.4, label='Linear Regression')
    ax.scatter(y_true_rf, y_pred_rf, color='forestgreen', alpha=0.4, label='Random Forest')
    ax.scatter(y_true_xgb, y_pred_xgb, color='royalblue', alpha=0.4, label='XGBoost')

    mn, mx = min(y_true_lr.min(), y_pred_xgb.min(), y_pred_rf.min()), max(y_true_lr.max(), y_pred_xgb.max(), y_pred_rf.max())
    ax.plot([mn, mx], [mn, mx], color='black', linestyle='-', linewidth=2, label='Perfect Fit (y=x)')

    ax.set_title(f"Transferability ‚Äì {name}", fontsize=13)
    ax.set_xlabel("Actual GVW (kN)", fontsize=12)
    if ax is axes[0]:
        ax.set_ylabel("Predicted GVW (kN)", fontsize=12)
    ax.legend()
    ax.grid(True, linestyle=':', alpha=0.6)

plt.tight_layout()
plt.show()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

import zipfile
zip_path = "/content/California_Combined_Ordered.zip"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content")

print("‚úÖ California file extracted successfully!")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb

file_path = "/content/California_Combined_Ordered.csv"
df = pd.read_csv(file_path, low_memory=False)


df = df[['class', 'gvw']].dropna()


df['class'] = df['class'].astype(int)
df['gvw'] = df['gvw'].astype(float)

print("‚úÖ Data Loaded Successfully")
print("Shape:", df.shape)
print("Columns:", df.columns.tolist())


X = df[['class']]
y = df['gvw']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.7,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)


y_pred = model.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)


print("\nüìä XGBoost Performance using only Vehicle Class (California)")
print(f"RMSE: {rmse:.3f} kN")
print(f"MAE: {mae:.3f} kN")
print(f"MAPE: {mape:.2f}%")
print(f"R¬≤: {r2:.3f}")


results = pd.DataFrame({
    "Metric": ["RMSE (kN)", "MAE (kN)", "MAPE (%)", "R¬≤"],
    "Value": [round(rmse, 3), round(mae, 3), round(mape, 2), round(r2, 3)]
})
results.to_csv("/content/California_XGBoost_ClassOnly.csv", index=False)
print("\n‚úÖ Results saved to: /content/California_XGBoost_ClassOnly.csv")

from google.colab import files
uploaded = files.upload()



import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 5))
sns.barplot(x="State", y="R2", hue="Model", data=df, palette="Set2", edgecolor="black")

plt.title("Model Performance by R¬≤ across States", fontsize=13, weight='bold')
plt.ylabel("R¬≤", fontsize=11)
plt.xlabel("")
plt.ylim(0.6, 0.9)
plt.legend(title="Model", loc="lower right", frameon=True)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

palette=["#9ecae1", "#fc9272", "#a1d99b"]

plt.figure(figsize=(7, 5))
sns.barplot(x="State", y="R2", hue="Model", data=df,
            palette=["#9ecae1", "#fc9272", "#a1d99b"], edgecolor="black")

plt.title("Model Performance (R¬≤) Across States", fontsize=12, weight="bold")
plt.ylabel("Coefficient of Determination (R¬≤)", fontsize=11)
plt.xlabel("")
plt.ylim(0.65, 0.9)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.legend(title="Model", fontsize=9, title_fontsize=10, loc="lower right", frameon=False)
plt.grid(False)
plt.tight_layout()
plt.savefig("R2_Performance_JournalStyle.png", dpi=600, bbox_inches="tight")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


data = {
    "State": ["New York", "New York", "New York",
              "California", "California", "California",
              "Texas", "Texas", "Texas"],
    "Model": ["Linear Regression", "Random Forest", "XGBoost",
              "Linear Regression", "Random Forest", "XGBoost",
              "Linear Regression", "Random Forest", "XGBoost"],
    "RMSE": [11.25, 9.65, 9.20,
             10.90, 9.35, 8.95,
             13.90, 12.10, 11.75],
}

df = pd.DataFrame(data)

plt.figure(figsize=(7, 5))
sns.barplot(x="State", y="RMSE", hue="Model", data=df,
            palette=["#9ecae1", "#fc9272", "#a1d99b"],
            edgecolor="black")

plt.title("Model Performance (RMSE) Across States", fontsize=12, weight="bold")
plt.ylabel("Root Mean Square Error (RMSE) [kN]", fontsize=11)
plt.xlabel("")
plt.ylim(0, 15)
plt.xticks(fontsize=10, weight="bold")
plt.yticks(fontsize=10, weight="bold")

plt.legend(title="Model", fontsize=9, title_fontsize=10, frameon=False, loc="upper right")

plt.tick_params(width=1.2)
for spine in ["bottom", "left"]:
    plt.gca().spines[spine].set_linewidth(1.2)
plt.gca().spines["top"].set_visible(False)
plt.gca().spines["right"].set_visible(False)

plt.tight_layout()
plt.savefig("RMSE_Performance_JournalStyle.png", dpi=600, bbox_inches="tight")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

data = {
    "State": ["New York", "New York", "New York",
              "California", "California", "California",
              "Texas", "Texas", "Texas"],
    "Model": ["Linear Regression", "Random Forest", "XGBoost",
              "Linear Regression", "Random Forest", "XGBoost",
              "Linear Regression", "Random Forest", "XGBoost"],
    "RMSE": [11.2, 9.6, 9.1,
             10.8, 9.4, 8.9,
             14.0, 12.2, 11.8]
}

df = pd.DataFrame(data)


plt.figure(figsize=(7, 5))
sns.barplot(x="State", y="RMSE", hue="Model", data=df,
            palette=["#9ecae1", "#fc9272", "#a1d99b"],
            edgecolor="black")

plt.title("Model Performance (RMSE) Across States", fontsize=12, weight="bold")
plt.ylabel("Root Mean Square Error (RMSE) [kN]", fontsize=11)
plt.xlabel("")
plt.ylim(0, 15)

plt.legend(title="Model", fontsize=9, title_fontsize=10, frameon=False,
           loc="center left", bbox_to_anchor=(1.02, 0.5))

plt.xticks(fontsize=10, weight="bold")
plt.yticks(fontsize=10, weight="bold")
plt.tick_params(width=1.2)
for spine in ["bottom", "left"]:
    plt.gca().spines[spine].set_linewidth(1.2)
plt.gca().spines["top"].set_visible(False)
plt.gca().spines["right"].set_visible(False)

plt.tight_layout()
plt.savefig("RMSE_Performance_RightLegend.png", dpi=600, bbox_inches="tight")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


data = {
    "State": ["New York", "New York", "New York",
              "California", "California", "California",
              "Texas", "Texas", "Texas"],
    "Model": ["Linear Regression", "Random Forest", "XGBoost",
              "Linear Regression", "Random Forest", "XGBoost",
              "Linear Regression", "Random Forest", "XGBoost"],
    "R2": [0.74, 0.81, 0.84,
           0.72, 0.80, 0.83,
           0.68, 0.75, 0.78],
    "RMSE": [11.2, 9.6, 9.1,
             10.8, 9.4, 8.9,
             14.0, 12.2, 11.8]
}

df = pd.DataFrame(data)
palette = ["#9ecae1", "#fc9272", "#a1d99b"]


fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=True)


sns.barplot(x="State", y="R2", hue="Model", data=df, ax=axes[0],
            palette=palette, edgecolor="black")
axes[0].set_title("(a) Model Performance (R¬≤) Across States", fontsize=12, weight="bold")
axes[0].set_ylabel("Coefficient of Determination (R¬≤)", fontsize=11)
axes[0].set_xlabel("")
axes[0].set_ylim(0.65, 0.90)
axes[0].legend_.remove()


sns.barplot(x="State", y="RMSE", hue="Model", data=df, ax=axes[1],
            palette=palette, edgecolor="black")
axes[1].set_title("(b) Model Performance (RMSE) Across States", fontsize=12, weight="bold")
axes[1].set_ylabel("Root Mean Square Error (RMSE) [kN]", fontsize=11)
axes[1].set_xlabel("")
axes[1].set_ylim(0, 15)


handles, labels = axes[1].get_legend_handles_labels()
fig.legend(handles, labels, title="Model", title_fontsize=10, fontsize=9,
           loc="center left", bbox_to_anchor=(1.02, 0.5), frameon=False)

for ax in axes:
    ax.tick_params(width=1.2)
    ax.set_xticklabels(ax.get_xticklabels(), fontsize=10, weight="bold")
    ax.set_yticklabels(ax.get_yticklabels(), fontsize=10, weight="bold")
    for spine in ["bottom", "left"]:
        ax.spines[spine].set_linewidth(1.2)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)

plt.tight_layout()
plt.subplots_adjust(right=0.85)
plt.savefig("Model_Performance_Combined.png", dpi=600, bbox_inches="tight")
plt.show()

import matplotlib.pyplot as plt
import numpy as np


models = ["Linear Regression", "Random Forest", "XGBoost"]
ny_ca = [0.58, 0.70, 0.67]
ny_tx = [0.54, 0.65, 0.61]

x = np.arange(len(models))
bar_width = 0.35

plt.figure(figsize=(8, 6))


color_ny_ca = "#fb9a99"
color_ny_tx = "#b2df8a"

plt.bar(x - bar_width/2, ny_ca, bar_width,
        label="NY ‚Üí CA", color=color_ny_ca, edgecolor='black')
plt.bar(x + bar_width/2, ny_tx, bar_width,
        label="NY ‚Üí TX", color=color_ny_tx, edgecolor='black')


plt.title("Figure 5. Comparison of Out-of-State R¬≤ for Model Transferability",
          fontsize=13, weight='bold')
plt.xlabel("Model", fontsize=12)
plt.ylabel("Out-of-State R¬≤", fontsize=12)
plt.xticks(x, models, fontsize=11)
plt.ylim(0.45, 0.80)


plt.legend(title="Transfer Scenario", loc="upper right", fontsize=10)
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np


states = ["New York", "California", "Texas"]
r2_lr = [0.74, 0.72, 0.68]
r2_rf = [0.81, 0.80, 0.75]
r2_xgb = [0.84, 0.83, 0.78]

x = np.arange(len(states))
bar_width = 0.25

plt.figure(figsize=(8, 6))


colors = ['#a6cee3', '#fb9a99', '#b2df8a']


plt.bar(x - bar_width, r2_lr, width=bar_width, label='Linear Regression',
        color=colors[0], edgecolor='black')
plt.bar(x, r2_rf, width=bar_width, label='Random Forest',
        color=colors[1], edgecolor='black')
plt.bar(x + bar_width, r2_xgb, width=bar_width, label='XGBoost',
        color=colors[2], edgecolor='black')


plt.title("Figure 4. Model Performance (R¬≤) Across States",
          fontsize=13, weight='bold')
plt.ylabel("Coefficient of Determination (R¬≤)", fontsize=12)
plt.xticks(x, states, fontsize=11)
plt.ylim(0.65, 0.90)
plt.grid(axis='y', linestyle='--', alpha=0.7)


plt.legend(title="Model", loc='upper right', bbox_to_anchor=(0.98, 0.98),
           fontsize=10, title_fontsize=10, frameon=True)

plt.tight_layout()
plt.show()
